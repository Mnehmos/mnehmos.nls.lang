"""
NLS CLI - Command-line interface for nlsc

Commands:
    nlsc init              Initialize a new NLS project
    nlsc compile <file>    Compile .nl file to target language
    nlsc verify <file>     Verify .nl file without generating
    nlsc graph <file>      Visualize dependencies and dataflow
    nlsc test <file>       Run @test specifications
"""

import argparse
import subprocess
import sys
import tempfile
from pathlib import Path

from . import __version__
from .parser import parse_nl_path, ParseError
from .resolver import resolve_dependencies
from .emitter import emit_python, emit_tests
from .lockfile import generate_lockfile, write_lockfile
from .graph import (
    emit_mermaid,
    emit_dot,
    emit_ascii,
    emit_dataflow_mermaid,
    emit_dataflow_ascii,
    emit_fsm_mermaid,
)


def cmd_init(args: argparse.Namespace) -> int:
    """Initialize a new NLS project"""
    project_dir = Path(args.path or ".")
    
    # Create project directory if it doesn't exist
    project_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"Initializing NLS project in {project_dir.absolute()}...")
    
    # Create config file
    config_path = project_dir / "nl.config.yaml"
    if not config_path.exists():
        config_content = """\
# NLS Project Configuration
# Generated by nlsc init

project:
  name: my-project
  version: 0.1.0

compiler:
  default_target: python
  llm_backend: mock  # mock, claude, openai, ollama
  cache_strategy: aggressive

targets:
  python:
    version: ">=3.11"
    style: black
    type_hints: strict

validation:
  require_purpose: true
  require_guards: false
  max_anlu_complexity: 10
"""
        config_path.write_text(config_content, encoding="utf-8")
        print(f"  ✓ Created {config_path.name}")
    else:
        print(f"  • {config_path.name} already exists")
    
    # Create directories
    src_dir = project_dir / "src"
    tests_dir = project_dir / "tests"
    
    for dir_path in [src_dir, tests_dir]:
        if not dir_path.exists():
            dir_path.mkdir(parents=True)
            print(f"  ✓ Created {dir_path.name}/")
        else:
            print(f"  • {dir_path.name}/ already exists")
    
    # Create __init__.py files
    for init_path in [src_dir / "__init__.py", tests_dir / "__init__.py"]:
        if not init_path.exists():
            init_path.write_text("", encoding="utf-8")
    
    print("\nNLS project initialized! Next steps:")
    print("  1. Create a .nl file in src/")
    print("  2. Run: nlsc compile src/your-file.nl")
    
    return 0


def cmd_compile(args: argparse.Namespace) -> int:
    """Compile a .nl file to target language"""
    source_path = Path(args.file)
    
    if not source_path.exists():
        print(f"Error: File not found: {source_path}", file=sys.stderr)
        return 1
    
    print(f"Compiling {source_path}...")
    
    # Parse
    try:
        nl_file = parse_nl_path(source_path)
        print(f"  ✓ Parsed {len(nl_file.anlus)} ANLUs")
    except ParseError as e:
        print(f"  ✗ Parse error: {e}", file=sys.stderr)
        return 1
    
    # Resolve dependencies
    result = resolve_dependencies(nl_file)
    if not result.success:
        print(f"  ✗ Resolution errors:", file=sys.stderr)
        for err in result.errors:
            print(f"    - {err.anlu_id}: {err.message}", file=sys.stderr)
        return 1
    print(f"  ✓ Resolved dependencies")
    
    # Emit Python
    target = args.target or "python"
    if target != "python":
        print(f"  ✗ Target '{target}' not yet supported", file=sys.stderr)
        return 1
    
    python_code = emit_python(nl_file, mode="mock")
    
    # Determine output path
    output_path = source_path.with_suffix(".py")
    if args.output:
        output_path = Path(args.output)
    
    output_path.write_text(python_code, encoding="utf-8")
    line_count = python_code.count("\n") + 1
    print(f"  ✓ Generated {output_path.name} ({line_count} lines)")
    
    # Generate tests if present
    test_code = emit_tests(nl_file)
    if test_code and nl_file.tests:
        test_path = source_path.parent / f"test_{source_path.stem}.py"
        test_path.write_text(test_code, encoding="utf-8")
        print(f"  ✓ Generated {test_path.name}")
    
    # Generate lockfile
    lock_path = source_path.with_suffix(".nl.lock")
    lockfile = generate_lockfile(
        nl_file,
        python_code,
        str(output_path),
        llm_backend="mock"
    )
    write_lockfile(lockfile, lock_path)
    print(f"  ✓ Updated {lock_path.name}")
    
    print(f"\nCompilation complete!")
    return 0


def cmd_verify(args: argparse.Namespace) -> int:
    """Verify a .nl file without generating code"""
    source_path = Path(args.file)
    
    if not source_path.exists():
        print(f"Error: File not found: {source_path}", file=sys.stderr)
        return 1
    
    print(f"Verifying {source_path}...")
    
    # Parse
    try:
        nl_file = parse_nl_path(source_path)
        print(f"  ✓ Syntax valid: {len(nl_file.anlus)} ANLUs")
    except ParseError as e:
        print(f"  ✗ Parse error: {e}", file=sys.stderr)
        return 1
    
    # Resolve
    result = resolve_dependencies(nl_file)
    if not result.success:
        print(f"  ✗ Resolution errors:")
        for err in result.errors:
            print(f"    - {err.anlu_id}: {err.message}")
        return 1
    print(f"  ✓ Dependencies valid")
    
    # Validate each ANLU
    errors = []
    for anlu in nl_file.anlus:
        if not anlu.purpose:
            errors.append(f"{anlu.identifier}: Missing PURPOSE")
        if not anlu.returns:
            errors.append(f"{anlu.identifier}: Missing RETURNS")
    
    if errors:
        print(f"  ✗ Validation errors:")
        for err in errors:
            print(f"    - {err}")
        return 1
    
    print(f"  ✓ All ANLUs valid")
    print(f"\nVerification passed!")
    return 0


def cmd_graph(args: argparse.Namespace) -> int:
    """Generate dependency graph visualization"""
    source_path = Path(args.file)

    if not source_path.exists():
        print(f"Error: File not found: {source_path}", file=sys.stderr)
        return 1

    # Parse
    try:
        nl_file = parse_nl_path(source_path)
    except ParseError as e:
        print(f"Parse error: {e}", file=sys.stderr)
        return 1

    output_format = args.format or "mermaid"
    anlu_id = args.anlu
    dataflow = args.dataflow

    # If specific ANLU requested
    if anlu_id:
        anlu = nl_file.get_anlu(anlu_id)
        if not anlu:
            print(f"Error: ANLU '{anlu_id}' not found", file=sys.stderr)
            print(f"Available: {', '.join(a.identifier for a in nl_file.anlus)}")
            return 1

        # Check if ANLU has FSM states
        has_fsm = bool(anlu.fsm_states())

        if output_format == "mermaid":
            if has_fsm and not dataflow:
                output = emit_fsm_mermaid(anlu)
            else:
                output = emit_dataflow_mermaid(anlu)
        elif output_format == "ascii":
            output = emit_dataflow_ascii(anlu)
        else:
            print(f"Error: Format '{output_format}' not supported for dataflow", file=sys.stderr)
            return 1
    else:
        # Full file dependency graph
        if output_format == "mermaid":
            output = emit_mermaid(nl_file)
        elif output_format == "dot":
            output = emit_dot(nl_file)
        elif output_format == "ascii":
            output = emit_ascii(nl_file)
        else:
            print(f"Error: Unknown format '{output_format}'", file=sys.stderr)
            return 1

    # Output
    if args.output:
        output_path = Path(args.output)
        output_path.write_text(output, encoding="utf-8")
        print(f"Graph written to {output_path}")
    else:
        print(output)

    return 0


def cmd_test(args: argparse.Namespace) -> int:
    """Run @test specifications from a .nl file"""
    source_path = Path(args.file)

    if not source_path.exists():
        print(f"Error: File not found: {source_path}", file=sys.stderr)
        return 1

    # Parse
    try:
        nl_file = parse_nl_path(source_path)
    except ParseError as e:
        print(f"Parse error: {e}", file=sys.stderr)
        return 1

    # Check for tests
    if not nl_file.tests:
        print(f"No @test blocks found in {source_path}")
        return 0

    # Create temp directory for generated code
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)

        # Generate the module code
        python_code = emit_python(nl_file, mode="mock")
        module_name = nl_file.module.name.replace("-", "_")
        module_path = temp_path / f"{module_name}.py"
        module_path.write_text(python_code, encoding="utf-8")

        # Generate the test code
        test_code = emit_tests(nl_file)
        if not test_code:
            print(f"No tests generated from {source_path}")
            return 0

        # Fix import to be direct (not relative)
        test_code = test_code.replace(f"from .{module_name} import *", f"from {module_name} import *")
        test_path = temp_path / f"test_{module_name}.py"
        test_path.write_text(test_code, encoding="utf-8")

        # Create __init__.py
        init_path = temp_path / "__init__.py"
        init_path.write_text("", encoding="utf-8")

        # Print summary
        total_cases = sum(len(ts.cases) for ts in nl_file.tests)
        print(f"Running {total_cases} test cases from {source_path}...")
        for ts in nl_file.tests:
            print(f"  • [{ts.anlu_id}]: {len(ts.cases)} cases")
        print()

        # Run pytest
        verbose_flag = "-v" if getattr(args, "verbose", False) else "-q"
        result = subprocess.run(
            [sys.executable, "-m", "pytest", str(test_path), verbose_flag, "--tb=short"],
            cwd=str(temp_path),
            capture_output=not getattr(args, "verbose", False),
            text=True,
            env={**__import__("os").environ, "PYTHONPATH": str(temp_path)}
        )

        # Report results
        if result.returncode == 0:
            print(f"✓ All {total_cases} tests passed!")
            return 0
        else:
            print(f"✗ Tests failed")
            if result.stdout:
                print(result.stdout)
            if result.stderr:
                print(result.stderr, file=sys.stderr)
            return 1


def main() -> int:
    """Main entry point for nlsc CLI"""
    parser = argparse.ArgumentParser(
        prog="nlsc",
        description="Natural Language Source Compiler",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""\
Examples:
  nlsc init                     Initialize new NLS project
  nlsc compile src/math.nl      Compile to Python
  nlsc verify src/auth.nl       Validate without generating
  nlsc graph src/order.nl       Generate Mermaid dependency diagram
  nlsc graph src/order.nl -a process-order  Visualize ANLU dataflow

The conversation is the programming. The .nl file is the receipt.
"""
    )
    parser.add_argument(
        "--version",
        action="version",
        version=f"nlsc {__version__}"
    )
    
    subparsers = parser.add_subparsers(dest="command", help="Available commands")
    
    # init command
    init_parser = subparsers.add_parser("init", help="Initialize NLS project")
    init_parser.add_argument(
        "path",
        nargs="?",
        default=".",
        help="Project directory (default: current)"
    )
    
    # compile command
    compile_parser = subparsers.add_parser("compile", help="Compile .nl file")
    compile_parser.add_argument(
        "file",
        help="Path to .nl file"
    )
    compile_parser.add_argument(
        "-t", "--target",
        default="python",
        help="Target language (default: python)"
    )
    compile_parser.add_argument(
        "-o", "--output",
        help="Output file path"
    )
    
    # verify command
    verify_parser = subparsers.add_parser("verify", help="Verify .nl file")
    verify_parser.add_argument(
        "file",
        help="Path to .nl file"
    )

    # graph command
    graph_parser = subparsers.add_parser(
        "graph",
        help="Visualize dependencies and dataflow"
    )
    graph_parser.add_argument(
        "file",
        help="Path to .nl file"
    )
    graph_parser.add_argument(
        "-f", "--format",
        choices=["mermaid", "dot", "ascii"],
        default="mermaid",
        help="Output format (default: mermaid)"
    )
    graph_parser.add_argument(
        "-a", "--anlu",
        help="Specific ANLU for dataflow visualization"
    )
    graph_parser.add_argument(
        "--dataflow",
        action="store_true",
        help="Show dataflow instead of FSM states"
    )
    graph_parser.add_argument(
        "-o", "--output",
        help="Output file path (default: stdout)"
    )

    # test command
    test_parser = subparsers.add_parser(
        "test",
        help="Run @test specifications"
    )
    test_parser.add_argument(
        "file",
        help="Path to .nl file"
    )
    test_parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="Verbose output"
    )

    args = parser.parse_args()
    
    if args.command is None:
        parser.print_help()
        return 0
    
    if args.command == "init":
        return cmd_init(args)
    elif args.command == "compile":
        return cmd_compile(args)
    elif args.command == "verify":
        return cmd_verify(args)
    elif args.command == "graph":
        return cmd_graph(args)
    elif args.command == "test":
        return cmd_test(args)

    return 0


if __name__ == "__main__":
    sys.exit(main())
